{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77412429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_25224\\1129593017.py:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('D:/research/data/IMDB_Dataset.csv', error_bad_lines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13441</th>\n",
       "      <td>I do not recommend this movie , because it's i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>I've been trying to find out about this series...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>This satire is just really, really dead-on, an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39364</th>\n",
       "      <td>When I was 13 or so I was lucky enough to find...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38714</th>\n",
       "      <td>Everyone who has ever wondered how to make a f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091</th>\n",
       "      <td>I found the episodes to be fascinating and wel...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48688</th>\n",
       "      <td>Rarely does a film capture such intense drama ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35092</th>\n",
       "      <td>with that, carry the same dark weaknesses we a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27211</th>\n",
       "      <td>This movie is probably one of 3 worst movies m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40915</th>\n",
       "      <td>A party-hardy frat boy's sister is brutally mu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "13441  I do not recommend this movie , because it's i...  negative\n",
       "2016   I've been trying to find out about this series...  positive\n",
       "3535   This satire is just really, really dead-on, an...  positive\n",
       "39364  When I was 13 or so I was lucky enough to find...  negative\n",
       "38714  Everyone who has ever wondered how to make a f...  positive\n",
       "10091  I found the episodes to be fascinating and wel...  positive\n",
       "48688  Rarely does a film capture such intense drama ...  positive\n",
       "35092  with that, carry the same dark weaknesses we a...  positive\n",
       "27211  This movie is probably one of 3 worst movies m...  negative\n",
       "40915  A party-hardy frat boy's sister is brutally mu...  negative"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('D:/research/data/IMDB_Dataset.csv', error_bad_lines=False)\n",
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bc6a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['sentiment'].replace(['positive', 'negative'],['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0ced02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36146</th>\n",
       "      <td>Sorry, but I usually love French thrillers - e...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23919</th>\n",
       "      <td>Dreamgirls, despite its fistful of Tony wins i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32592</th>\n",
       "      <td>Raising Victor Vargas: A Review&lt;br /&gt;&lt;br /&gt;You...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35994</th>\n",
       "      <td>This is the ultimate Kung Fu movie! This is th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47242</th>\n",
       "      <td>\"Come Undone\" appears to elicit a lot of opini...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48261</th>\n",
       "      <td>I'm surprised by some of the comments on this ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22094</th>\n",
       "      <td>if you're a sucker for corny movies and are lo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25731</th>\n",
       "      <td>Okay, here's what I think about Jack Frost. I ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>This is the movie that epitomizes the D&amp;D fear...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46145</th>\n",
       "      <td>Successful films on metaphysical subjects are ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment label\n",
       "36146  Sorry, but I usually love French thrillers - e...  negative     0\n",
       "23919  Dreamgirls, despite its fistful of Tony wins i...  negative     0\n",
       "32592  Raising Victor Vargas: A Review<br /><br />You...  negative     0\n",
       "35994  This is the ultimate Kung Fu movie! This is th...  negative     0\n",
       "47242  \"Come Undone\" appears to elicit a lot of opini...  positive     1\n",
       "48261  I'm surprised by some of the comments on this ...  positive     1\n",
       "22094  if you're a sucker for corny movies and are lo...  negative     0\n",
       "25731  Okay, here's what I think about Jack Frost. I ...  positive     1\n",
       "5841   This is the movie that epitomizes the D&D fear...  negative     0\n",
       "46145  Successful films on metaphysical subjects are ...  positive     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "032a1254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f657e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('D:/research/data/IMDB_Dataset_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a20d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing for sentiment analysis\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #1. Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    text_blob = TextBlob(text)\n",
    "    text = ' '.join(text_blob.words)\n",
    "    \n",
    "    #2. clean the number \n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    #3. lower the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #4. conver the emoji to text form\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    #5. remove punctuation \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    \n",
    "    #6. tokenize the text\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    #7. remove empty token\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    \n",
    "    #8. remove non-alphabetical token\n",
    "    text = [t for t in text if t.isalpha()]\n",
    "    \n",
    "    #9. replace the negation token\n",
    "    replacer  = AntonymReplacer()\n",
    "    text = replacer.replace_negations(text)\n",
    "    \n",
    "    #10. remove the stopwords\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "    \n",
    "    #11. stem the text\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    text = [porter_stemmer.stem(w) for w in text]\n",
    "    \n",
    "    return text\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def replace_negations(self, sent):\n",
    "        i, l = 0, len(sent)\n",
    "        words = []\n",
    "\n",
    "        while i < l:\n",
    "            word = sent[i]\n",
    "\n",
    "            if word == 'not' and i+1 < l:\n",
    "                ant = self.replace(sent[i+1])\n",
    "\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a40e6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So im not a big fan of Boll's work but then again not many are. I enjoyed his movie Postal (maybe im the only one). Boll apparently bought the rights to use Far Cry long ago even before the game itself was even finsished. <br /><br />People who have enjoyed killing mercs and infiltrating secret research labs located on a tropical island should be warned, that this is not Far Cry... This is something Mr Boll have schemed together along with his legion of schmucks.. Feeling loneley on the set Mr Boll invites three of his countrymen to play with. These players go by the names of Til Schweiger, Udo Kier and Ralf Moeller.<br /><br />Three names that actually have made them selfs pretty big in the movie biz. So the tale goes like this, Jack Carver played by Til Schweiger (yes Carver is German all hail the bratwurst eating dudes!!) However I find that Tils acting in this movie is pretty badass.. People have complained about how he's not really staying true to the whole Carver agenda but we only saw carver in a first person perspective so we don't really know what he looked like when he was kicking a**.. <br /><br />However, the storyline in this film is beyond demented. We see the evil mad scientist Dr. Krieger played by Udo Kier, making Genetically-Mutated-soldiers or GMS as they are called. Performing his top-secret research on an island that reminds me of \"SPOILER\" Vancouver for some reason. Thats right no palm trees here. Instead we got some nice rich lumberjack-woods. We haven't even gone FAR before I started to CRY (mehehe) I cannot go on any more.. If you wanna stay true to Bolls shenanigans then go and see this movie you will not be disappointed it delivers the true Boll experience, meaning most of it will suck.<br /><br />There are some things worth mentioning that would imply that Boll did a good work on some areas of the film such as some nice boat and fighting scenes. Until the whole cromed/albino GMS squad enters the scene and everything just makes me laugh.. The movie Far Cry reeks of scheisse (that's poop for you simpletons) from a fa,r if you wanna take a wiff go ahead.. BTW Carver gets a very annoying sidekick who makes you wanna shoot him the first three minutes he's on screen.\n",
      "['im', 'big', 'fan', 'boll', 'work', 'enjoy', 'movi', 'postal', 'mayb', 'im', 'one', 'boll', 'appar', 'bought', 'right', 'use', 'far', 'cri', 'long', 'ago', 'even', 'game', 'even', 'finsish', 'br', 'br', 'peopl', 'enjoy', 'kill', 'merc', 'infiltr', 'secret', 'research', 'lab', 'locat', 'tropic', 'island', 'warn', 'near', 'cri', 'someth', 'mr', 'boll', 'scheme', 'togeth', 'along', 'legion', 'schmuck', 'feel', 'loneley', 'set', 'mr', 'boll', 'invit', 'three', 'countrymen', 'play', 'player', 'go', 'name', 'til', 'schweiger', 'udo', 'kier', 'ralf', 'moeller', 'br', 'br', 'three', 'name', 'actual', 'made', 'self', 'pretti', 'big', 'movi', 'biz', 'tale', 'goe', 'like', 'jack', 'carver', 'play', 'til', 'schweiger', 'ye', 'carver', 'german', 'hail', 'bratwurst', 'eat', 'dude', 'howev', 'find', 'til', 'act', 'movi', 'pretti', 'badass', 'peopl', 'complain', 'realli', 'stay', 'true', 'whole', 'carver', 'agenda', 'saw', 'carver', 'first', 'person', 'perspect', 'nt', 'realli', 'know', 'look', 'like', 'kick', 'br', 'br', 'howev', 'storylin', 'film', 'beyond', 'dement', 'see', 'evil', 'mad', 'scientist', 'dr', 'krieger', 'play', 'udo', 'kier', 'make', 'geneticallymutatedsoldi', 'gm', 'call', 'perform', 'topsecret', 'research', 'island', 'remind', 'spoiler', 'vancouv', 'reason', 'that', 'right', 'palm', 'tree', 'instead', 'got', 'nice', 'rich', 'lumberjackwood', 'nt', 'even', 'gone', 'far', 'start', 'cri', 'meheh', 'go', 'wan', 'na', 'stay', 'true', 'boll', 'shenanigan', 'go', 'see', 'movi', 'differ', 'disappoint', 'deliv', 'true', 'boll', 'experi', 'mean', 'suck', 'br', 'br', 'thing', 'worth', 'mention', 'would', 'impli', 'boll', 'good', 'work', 'area', 'film', 'nice', 'boat', 'fight', 'scene', 'whole', 'cromedalbino', 'gm', 'squad', 'enter', 'scene', 'everyth', 'make', 'laugh', 'movi', 'far', 'cri', 'reek', 'scheiss', 'poop', 'simpleton', 'fa', 'r', 'wan', 'na', 'take', 'wiff', 'go', 'ahead', 'btw', 'carver', 'get', 'annoy', 'sidekick', 'make', 'wan', 'na', 'shoot', 'first', 'three', 'minut', 'screen']\n"
     ]
    }
   ],
   "source": [
    "print(data['review'].iloc[12])\n",
    "print(preprocess(data['review'].iloc[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a66e9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\"\"\"\n",
    "min_df=2, discard words appearing in less than 2 documents\n",
    "max_df=0.9, discard words appering in more than 90% of the documents\n",
    "sublinear_tf=True, use sublinear weighting\n",
    "use_idf=True, enable IDF\n",
    "\"\"\"\n",
    "vec = TfidfVectorizer(\n",
    "    analyzer=preprocess,\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "tfidf_model = vec.fit(data['review'])\n",
    "train_vec = vec.transform(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a29ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#save vectorizer\n",
    "vectorizer_file = 'D:/research/models/tfidf_vectorizer.sav';\n",
    "pickle.dump(tfidf_model, open(vectorizer_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "319cef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 4000\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_vec, \n",
    "                                            data.label, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ab3c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40000, 45394)\n",
      "X_test shape: (10000, 45394)\n",
      "y_train shape: (40000,)\n",
      "y_test shape: (10000,)\n",
      "Result of MultinomialNB\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      5085\n",
      "           1       0.85      0.87      0.86      4915\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[4344  741]\n",
      " [ 662 4253]]\n",
      "\n",
      "\n",
      "Accuracy score:  0.8597\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Result of RandomForest\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      5001\n",
      "           1       0.85      0.85      0.85      4999\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[4276  725]\n",
      " [ 730 4269]]\n",
      "\n",
      "\n",
      "Accuracy score:  0.8545\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.33, random_state=39)\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))\n",
    "\n",
    "# pick Multinomial Naive Bayes and RandomForest algorithms \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_mnb = MultinomialNB()\n",
    "clf_rfc = RandomForestClassifier(random_state=39)\n",
    "\n",
    "clf_names = ['MultinomialNB', 'RandomForest']\n",
    "clf_types = [clf_mnb, clf_rfc]\n",
    "\n",
    "for (i, clf) in enumerate(clf_types):\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    print('Result of {}\\n'.format(clf_names[i]))\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(classification_report(predictions, y_test))\n",
    "    print('\\n')\n",
    "    print('Confusion matrix: \\n', confusion_matrix(predictions, y_test))\n",
    "    print('\\n')\n",
    "    print('Accuracy score: ', accuracy_score(predictions, y_test))\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65408e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename1 = 'D:/research/models/MultinomialNB_sentiment_model.sav'\n",
    "pickle.dump(clf_mnb, open(filename1, 'wb'))\n",
    "\n",
    "filename2 = 'D:/research/models/RandomForest_sentiment_model.sav'\n",
    "pickle.dump(clf_rfc, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cb0e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename1 = 'D:/research/models/MultinomialNB_sentiment_model.sav' #load trained model\n",
    "loaded_clf_mnb_model = pickle.load(open(filename1, 'rb'))\n",
    "\n",
    "filename2 = 'D:/research/models/RandomForest_sentiment_model.sav'#load trained model\n",
    "loaded_clf_rfc_model = pickle.load(open(filename2, 'rb'))\n",
    "\n",
    "tfidf_vectorizer = 'D:/research/models/tfidf_vectorizer.sav';\n",
    "loaded_tfidf_vectorizer = pickle.load(open(tfidf_vectorizer, 'rb'))#load save vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c8762be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['provid', 'better', 'care', 'choic', 'lower', 'cost']\n"
     ]
    }
   ],
   "source": [
    "tweet = 'We are providing better care, and more choice, at lower cost.'\n",
    "preprocess_tweet = preprocess(tweet)\n",
    "print(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06b48d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"negative\" has been predicted for the tweet: We are providing better care, and more choice, at lower cost.\n"
     ]
    }
   ],
   "source": [
    "# vectorize the tweet\n",
    "tweet_vec = loaded_tfidf_vectorizer.transform(pd.Series([tweet]))\n",
    "\n",
    "# predict a label using Multinomial Naive Bayes\n",
    "tweet_prediction = loaded_clf_mnb_model.predict(tweet_vec.toarray())\n",
    "tweet_prediction = 'positive' if tweet_prediction[0] == '1' else 'negative'\n",
    "print('\"{}\" has been predicted for the tweet: {}'.format(tweet_prediction, tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "755a4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"positive\" has been predicted for the tweet: We are providing better care, and more choice, at lower cost.\n"
     ]
    }
   ],
   "source": [
    "# predict a label using RandomForest\n",
    "\n",
    "tweet_prediction = loaded_clf_rfc_model.predict(tweet_vec.toarray())\n",
    "tweet_prediction = 'positive' if tweet_prediction[0] == '1' else 'negative'\n",
    "print('\"{}\" has been predicted for the tweet: {}'.format(tweet_prediction, tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6c8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
